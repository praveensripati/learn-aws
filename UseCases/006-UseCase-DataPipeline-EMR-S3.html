<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Verdana;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:10.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:10.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
p.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:10.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:11.0pt;
	font-family:"Calibri",sans-serif;}
.MsoChpDefault
	{font-family:"Calibri",sans-serif;}
.MsoPapDefault
	{margin-bottom:10.0pt;
	line-height:115%;}
@page WordSection1
	{size:595.3pt 841.9pt;
	margin:.5in .5in .5in .5in;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

</head>

<body lang=EN-US link=blue vlink=purple style='word-wrap:break-word'>

<div class=WordSection1>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><b><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>Use Case</span></b></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>In the previous
use case, we have uploaded around 3.4 GB of airline data set from the Hardvard
Dataverse into S3 and did analytics using a combination of Athena and
QuickSight. This was all fine and dandy, but the only problem was that we had
to do most of the tasks manually.</span></p>

<p class=MsoNormal align=center style='margin-bottom:0in;text-align:center;
line-height:normal'><span lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'><img
width=410 height=136 id="Picture 1"
src="006-UseCase-DataPipeline-EMR-S3_files/image001.png"></span></p>

<p class=MsoNormal align=center style='margin-bottom:0in;text-align:center;
line-height:normal'><span lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>In the
corporate setup where we do a lot of analytics to get some meaningful insights,
performing tasks manually takes a lot of time and also prone to error. This is
where </span><span lang=EN-IN><a href="https://aws.amazon.com/datapipeline/"><span
style='font-size:12.0pt;font-family:"Verdana",sans-serif'>AWS Data Pipeline</span></a></span><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'> and </span><span
lang=EN-IN><a href="https://aws.amazon.com/glue/"><span style='font-size:12.0pt;
font-family:"Verdana",sans-serif'>AWS Glue</span></a></span><span lang=EN-IN
style='font-size:12.0pt;font-family:"Verdana",sans-serif'> comes into play. In
this use case we would be using Data Pipeline to create a pipeline with a set
of activities to analyse the data in S3. Since, we have already uploaded a big
data set into S3, we would be leveraging the same.</span></p>

<p class=MsoNormal align=center style='margin-bottom:0in;text-align:center;
line-height:normal'><span lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal align=center style='margin-bottom:0in;text-align:center;
line-height:normal'><span lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'><img
border=0 width=348 height=220 id="Picture 2"
src="006-UseCase-DataPipeline-EMR-S3_files/image002.png"></span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>We would
try to automate the below activities in the AWS Data Pipeline, the same is
represented in the above diagram also.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoListParagraphCxSpFirst style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:.75in;text-indent:-.25in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>-<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>Set a
precondition to see if the data is there in S3</span></p>

<p class=MsoListParagraphCxSpMiddle style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:.75in;text-indent:-.25in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>-<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>Create an
EMR Cluster using the Spot Instances</span></p>

<p class=MsoListParagraphCxSpMiddle style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:.75in;text-indent:-.25in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>-<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>If the
Cluster has not been created, then use the On Demand Instances</span></p>

<p class=MsoListParagraphCxSpMiddle style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:.75in;text-indent:-.25in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>-<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>Perform
analytics to figure out the busiest airport over years</span></p>

<p class=MsoListParagraphCxSpLast style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:.75in;text-indent:-.25in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>-<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>Tear down
the entire setup</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>The entire
thing would be done using Hive Queries and so we need an EMR Cluster for the
same. AWS Data Pipeline also automates the process of creating the EMR Cluster
and then we should be able to do the data formation and analytics on the same.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>Once a
pipeline has been created, the same can be scheduled at regular intervals or
can be executed on demand. Again, as in the previous use case we will try to
get some interesting insights from real data.</span></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><b><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>&nbsp;</span></b></p>

<p class=MsoNormal style='margin-bottom:0in;line-height:normal'><b><span
lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>AWS
Services: </span></b><span lang=EN-IN style='font-size:12.0pt;font-family:"Verdana",sans-serif'>S3,
EMR, Data Pipeline.</span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Create a Security Group from the EC2
Management Console and allow 22/SSH inbound for everyone as shown below. Note
down the “Security Group ID”.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 38" src="006-UseCase-DataPipeline-EMR-S3_files/image003.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 39" src="006-UseCase-DataPipeline-EMR-S3_files/image004.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Create a Key Pair and note down the name.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 40" src="006-UseCase-DataPipeline-EMR-S3_files/image005.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Go to the SNS Management Console and
create a Topic. Make sure to note down the Topic ARN.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 41" src="006-UseCase-DataPipeline-EMR-S3_files/image006.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
-- Subscribe to the Topic via Email and make sure that the status of the
Subscription is confirmed.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 42" src="006-UseCase-DataPipeline-EMR-S3_files/image007.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Create a bucket in S3 with a folder called
“input” and upload the Airline dataset into it. The data can be downloaded from
the Harvard Dataverse Site (</span><span lang=EN-IN><a
href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HG7NV7"><span
style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'>here</span></a></span><span
lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'>).
If this step has been performed for the previous use case there is no need to
perform it again. Again note down the bucket name.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>Depending on your network bandwidth, try to
download/upload the appropriate amount of data. Note that S3 provides only up
to 5GB of storage for free.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 43" src="006-UseCase-DataPipeline-EMR-S3_files/image008.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
-- Create a “logs” folder in the same bucket.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 44" src="006-UseCase-DataPipeline-EMR-S3_files/image009.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Create a file called “emr-datapipeline.json”
with the below content and make sure to change the highlighted sections with
the details noted in the previous steps. Also, note down the latest EMR release
from the below URL and replace “emr-5.30.1” with the lasts one.</span></p>

<p class=MsoNormal><span lang=EN-IN><a
href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html"><span
style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'>https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html</span></a></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:10.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>{<br>
  &quot;objects&quot;: [<br>
    {<br>
      &quot;failureAndRerunMode&quot;: &quot;CASCADE&quot;,<br>
      &quot;resourceRole&quot;: &quot;DataPipelineDefaultResourceRole&quot;,<br>
      &quot;role&quot;: &quot;DataPipelineDefaultRole&quot;,<br>
      &quot;pipelineLogUri&quot;: &quot;s3://<b><span style='color:red'>airline-dataset-praveen</span></b>/logs/&quot;,<br>
      &quot;scheduleType&quot;: &quot;ONDEMAND&quot;,<br>
      &quot;name&quot;: &quot;Default&quot;,<br>
      &quot;id&quot;: &quot;Default&quot;<br>
    },<br>
    {<br>
      &quot;role&quot;: &quot;DataPipelineDefaultRole&quot;,<br>
      &quot;subject&quot;: &quot;Hive Ran Successfully&quot;,<br>
      &quot;name&quot;: &quot;SuccessNotification&quot;,<br>
      &quot;id&quot;: &quot;ActionId_Y3WGh&quot;,<br>
      &quot;message&quot;: &quot;Hive Ran Successfully&quot;,<br>
      &quot;type&quot;: &quot;SnsAlarm&quot;,<br>
      &quot;topicArn&quot;: &quot;<b><span style='color:red'>arn:aws:sns:us-east-1:304000509264:MyEMRTopic</span></b>&quot;<br>
    },<br>
    {<br>
      &quot;role&quot;: &quot;DataPipelineDefaultRole&quot;,<br>
      &quot;subject&quot;: &quot;Hive Ran Failure&quot;,<br>
      &quot;name&quot;: &quot;FailureNotification&quot;,<br>
      &quot;id&quot;: &quot;ActionId_75ocL&quot;,<br>
      &quot;message&quot;: &quot;Hive Ran Failure&quot;,<br>
      &quot;type&quot;: &quot;SnsAlarm&quot;,<br>
      &quot;topicArn&quot;: &quot;<b><span style='color:red'>arn:aws:sns:us-east-1:304000509264:MyEMRTopic</span></b>&quot;<br>
    },<br>
    {<br>
      &quot;maximumRetries&quot;: &quot;1&quot;,<br>
      &quot;role&quot;: &quot;DataPipelineDefaultRole&quot;,<br>
      &quot;s3Key&quot;: &quot;s3://<b><span style='color:red'>airline-dataset-praveen</span></b>/input/1987.csv&quot;,<br>
      &quot;name&quot;: &quot;CheckIfInputExists&quot;,<br>
      &quot;id&quot;: &quot;PreconditionId_3V3Y8&quot;,<br>
      &quot;type&quot;: &quot;S3KeyExists&quot;<br>
    },<br>
    {<br>
      &quot;maximumRetries&quot;: &quot;1&quot;,<br>
      &quot;useOnDemandOnLastAttempt&quot;: &quot;true&quot;,<br>
      &quot;coreInstanceBidPrice&quot;: &quot;19&quot;,<br>
      &quot;coreInstanceCount&quot;: &quot;1&quot;,<br>
      &quot;masterInstanceType&quot;: &quot;m5.xlarge&quot;,<br>
      &quot;releaseLabel&quot;: &quot;<b><span style='color:red'>emr-5.30.1</span></b>&quot;,<br>
      &quot;type&quot;: &quot;EmrCluster&quot;,<br>
      &quot;attemptTimeout&quot;: &quot;15 Minutes&quot;,<br>
      &quot;terminateAfter&quot;: &quot;60 Minutes&quot;,<br>
      &quot;name&quot;: &quot;EMR-Cluster-For-AirlineData&quot;,<br>
      &quot;coreInstanceType&quot;: &quot;m5.xlarge&quot;,<br>
      &quot;keyPair&quot;: &quot;<b><span style='color:red'>my-keypair</span></b>&quot;,<br>
      &quot;id&quot;: &quot;EmrClusterId_oOXSg&quot;,<br>
      &quot;masterInstanceBidPrice&quot;: &quot;19&quot;,<br>
      &quot;additionalMasterSecurityGroupIds&quot;: &quot;<b><span
style='color:red'>sg-0fa7df1dab4d7ebcb</span></b>&quot;<br>
    },<br>
    {<br>
      &quot;directoryPath&quot;: &quot;s3://<b><span style='color:red'>airline-dataset-praveen</span></b>/input/&quot;,<br>
      &quot;dataFormat&quot;: {<br>
        &quot;ref&quot;: &quot;DataFormatId_FBIwP&quot;<br>
      },<br>
      &quot;name&quot;: &quot;S3Node-CSV-Data&quot;,<br>
      &quot;precondition&quot;: {<br>
        &quot;ref&quot;: &quot;PreconditionId_3V3Y8&quot;<br>
      },<br>
      &quot;id&quot;: &quot;DataNodeId_o4MSC&quot;,<br>
      &quot;type&quot;: &quot;S3DataNode&quot;<br>
    },<br>
    {<br>
      &quot;column&quot;: [<br>
        &quot;Year INT&quot;,<br>
        &quot;Month INT&quot;,<br>
        &quot;DayofMonth INT&quot;,<br>
        &quot;DayOfWeek INT&quot;,<br>
        &quot;DepTime INT&quot;,<br>
        &quot;CRSDepTime INT&quot;,<br>
        &quot;ArrTime INT&quot;,<br>
        &quot;CRSArrTime INT&quot;,<br>
        &quot;UniqueCarrier STRING&quot;,<br>
        &quot;FlightNum INT&quot;,<br>
        &quot;TailNum STRING&quot;,<br>
        &quot;ActualElapsedTime INT&quot;,<br>
        &quot;CRSElapsedTime INT&quot;,<br>
        &quot;AirTime INT&quot;,<br>
        &quot;ArrDelay INT&quot;,<br>
        &quot;DepDelay INT&quot;,<br>
        &quot;Origin STRING&quot;,<br>
        &quot;Dest STRING&quot;,<br>
        &quot;Distance INT&quot;,<br>
        &quot;TaxiIn INT&quot;,<br>
        &quot;TaxiOut INT&quot;,<br>
        &quot;Cancelled INT&quot;,<br>
        &quot;CancellationCode STRING&quot;,<br>
        &quot;Diverted STRING&quot;,<br>
        &quot;CarrierDelay INT&quot;,<br>
        &quot;WeatherDelay INT&quot;,<br>
        &quot;NASDelay INT&quot;,<br>
        &quot;SecurityDelay INT&quot;,<br>
        &quot;LateAircraftDelay INT&quot;<br>
      ],<br>
      &quot;name&quot;: &quot;CSV-Input&quot;,<br>
      &quot;id&quot;: &quot;DataFormatId_FBIwP&quot;,<br>
      &quot;type&quot;: &quot;CSV&quot;<br>
    },<br>
    {<br>
      &quot;directoryPath&quot;: &quot;s3://<b><span style='color:red'>airline-dataset-praveen</span></b>/final-results&quot;,<br>
      &quot;dataFormat&quot;: {<br>
        &quot;ref&quot;: &quot;DataFormatId_0iWke&quot;<br>
      },<br>
      &quot;name&quot;: &quot;S3Node-FInal-Results&quot;,<br>
      &quot;id&quot;: &quot;DataNodeId_3Fjg6&quot;,<br>
      &quot;type&quot;: &quot;S3DataNode&quot;<br>
    },<br>
    {<br>
      &quot;column&quot;: [<br>
        &quot;Origin INT&quot;,<br>
        &quot;Total INT&quot;<br>
      ],<br>
      &quot;name&quot;: &quot;CSV-Output&quot;,<br>
      &quot;id&quot;: &quot;DataFormatId_0iWke&quot;,<br>
      &quot;type&quot;: &quot;CSV&quot;<br>
    },<br>
    {<br>
      &quot;maximumRetries&quot;: &quot;0&quot;,<br>
      &quot;output&quot;: {<br>
        &quot;ref&quot;: &quot;DataNodeId_3Fjg6&quot;<br>
      },<br>
      &quot;input&quot;: {<br>
        &quot;ref&quot;: &quot;DataNodeId_o4MSC&quot;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:10.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>      },<br>
      &quot;stage&quot;: &quot;true&quot;,<br>
      &quot;onFail&quot;: {<br>
        &quot;ref&quot;: &quot;ActionId_75ocL&quot;<br>
      },<br>
      &quot;name&quot;: &quot;AnalyzeData&quot;,<br>
      &quot;hiveScript&quot;: &quot;delete jar
/mnt/taskRunner/emr-hive-goodies.jar;INSERT OVERWRITE TABLE ${output1} select
Origin, count(*) As Total from ${input1} group by Origin order by Total;&quot;,<br>
      &quot;id&quot;: &quot;HiveActivityId_ySH25&quot;,<br>
      &quot;runsOn&quot;: {<br>
        &quot;ref&quot;: &quot;EmrClusterId_oOXSg&quot;<br>
      },<br>
      &quot;type&quot;: &quot;HiveActivity&quot;,<br>
      &quot;onSuccess&quot;: {<br>
        &quot;ref&quot;: &quot;ActionId_Y3WGh&quot;<br>
      }<br>
    }<br>
  ],<br>
  &quot;parameters&quot;: []<br>
}</span></p>

<span lang=EN-IN style='font-size:10.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:10.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- There are tons of ways of modifying the
JSON. Using the VS Code makes it easy to change the file. The same can be
downloaded from the below URL.</span></p>

<p class=MsoNormal><span lang=EN-IN><a href="https://code.visualstudio.com/"><span
style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'>https://code.visualstudio.com/</span></a></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=698 height=379
id="Picture 45" src="006-UseCase-DataPipeline-EMR-S3_files/image010.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Go to the AWS Data Pipeline Management
Console and click on “Get started now”.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 46" src="006-UseCase-DataPipeline-EMR-S3_files/image011.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Give some name for the Data Pipeline.
Click on “Import a definition”, “Load local file” and point to the JSON file
which was created earlier. For the schedule, select “on pipeline activation”.
Finally click on “Edit in Architect”.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 47" src="006-UseCase-DataPipeline-EMR-S3_files/image012.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- A DAG (Directed Acyclic Graph) will be
displayed as shown below with the Activities, DataNodes, Schedules, Resources,
Preconditions etc. Click on “Activate”.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>Here Data Pipeline would be automatically checking
if the input data exists in S3, create an EMR Cluster and once it ready execute
a Hive script to output the results to S3.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 48" src="006-UseCase-DataPipeline-EMR-S3_files/image013.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- In the “Filter” select “All” to display
the “Component name” and “Status”.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 49" src="006-UseCase-DataPipeline-EMR-S3_files/image014.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Go to the “EMR Management Console” and
there should be an EMR Cluster in the “Starting” status.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 50" src="006-UseCase-DataPipeline-EMR-S3_files/image015.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Click on the Cluster name to see the
Summary and Details of the Cluster.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=698 height=347
id="Picture 51" src="006-UseCase-DataPipeline-EMR-S3_files/image016.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Click on the Hardware and notice that the
EC2 instances are in a provisioned state. Luckily we were able to get the EC2
instances with the Spot pricing. For some reason if the Spot instances are not
available, then the EMR Cluster creation will be retried with On Demand pricing
to make sure we get the desired EC2 instances for setting up the EMR Cluster.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 52" src="006-UseCase-DataPipeline-EMR-S3_files/image017.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
-- Click on the Steps tab and see that the installation of the softwares and
boot strapping is in a pending state.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 53" src="006-UseCase-DataPipeline-EMR-S3_files/image018.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Go to the EC2 Management Console and we
see that there two EC2 instances, one for the master and the other for the
slave. For the convenience they have been named appropriately. Which is what
can be got by looking at the Security Group attached to the EC2 instance. Note
that for the Master EC2 instance the AllowSSH Security Group is automatically
attached, so we should be able to connect to it for the sake of
debugging/troubleshooting.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=698 height=347
id="Picture 54" src="006-UseCase-DataPipeline-EMR-S3_files/image019.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=698 height=347
id="Picture 55" src="006-UseCase-DataPipeline-EMR-S3_files/image020.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Open Putty and specify
“username@master-ip-address” as shown below.</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-IN
style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><img
border=0 width=402 height=360 id="Picture 56"
src="006-UseCase-DataPipeline-EMR-S3_files/image021.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Go “Connection </span><span lang=EN-IN
style='font-size:12.0pt;line-height:115%;font-family:Wingdings'>à</span><span
lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'>
SSH </span><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:Wingdings'>à</span><span lang=EN-IN style='font-size:12.0pt;
line-height:115%;font-family:"Verdana",sans-serif'> Auth” and in the “Private
key file for authentication”, browse and point to the Private Key in the PPK
format. Click on “Open” and we would be connected to the EC2 instance.</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-IN
style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><img
border=0 width=390 height=352 id="Picture 57"
src="006-UseCase-DataPipeline-EMR-S3_files/image022.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- We would be connected to the Master EC2
instance as shown below.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=387
id="Picture 58" src="006-UseCase-DataPipeline-EMR-S3_files/image023.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- In around 7 minutes the EMR Cluster would
be in a “Waiting” state for the Steps (Big Data tasks) to be executed. The same
can be observed from the EMR Management Console.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=698 height=347
id="Picture 59" src="006-UseCase-DataPipeline-EMR-S3_files/image024.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
-- Also, under the Steps tab the “Install TaskRunner” would be in a “Completed”
Status. This means that the EMR Cluster is ready for the Hive Script to
executed.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 60" src="006-UseCase-DataPipeline-EMR-S3_files/image025.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- In the Data Pipeline Management Console,
we can notice that the EmrCluster and the AnalyzeData (Hive Script) would also
be in a RUNNING status. This means that the Hive Script is getting executed on
the EMR Cluster. </span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 61" src="006-UseCase-DataPipeline-EMR-S3_files/image026.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
<br>
</span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Expand the “AnalyzeData” action and click
on the refresh button beside it and the log files would be available in a few
minutes. These log files would be definitely useful for
debugging/troubleshooting any problems.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 62" src="006-UseCase-DataPipeline-EMR-S3_files/image027.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 63" src="006-UseCase-DataPipeline-EMR-S3_files/image028.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- In a few minutes, the “AnalyzeData” and
the “S3Node-Final-Results” are in a FINISHED status. This means that the Hive
Script has been successfully executed and the results have been written to S3.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 64" src="006-UseCase-DataPipeline-EMR-S3_files/image029.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
-- Also, we would be getting an email that the Hive Script ran through
successfully from the SNS.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 65" src="006-UseCase-DataPipeline-EMR-S3_files/image030.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- Here is the output of the Hive script in
S3. The same has been attached for reference. By downloading and opening this
file from S3, we get the busiest and the idle airports based on the number of
flight departures from a particular airport across multiple years. Once the
Hive script starts executing, it takes about 2 minutes to process 3.4 GB of
data.</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-IN><img
border=0 width=102 height=66
src="006-UseCase-DataPipeline-EMR-S3_files/image031.png"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 66" src="006-UseCase-DataPipeline-EMR-S3_files/image032.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><br>
-- Since the Hive script ran through, the EMR cluster would be automatically
terminated. The same can be observed from the EMR Management Console. The EC2
instances also would be automatically terminated.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=698 height=347
id="Picture 67" src="006-UseCase-DataPipeline-EMR-S3_files/image033.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- In the Data Pipeline Management Console,
all the Components would be in a FINISHED status.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 68" src="006-UseCase-DataPipeline-EMR-S3_files/image034.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>-- In the Data Pipeline Management Console,
select the pipeline and delete it.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 69" src="006-UseCase-DataPipeline-EMR-S3_files/image035.jpg"></span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'><img border=0 width=697 height=346
id="Picture 70" src="006-UseCase-DataPipeline-EMR-S3_files/image036.jpg"></span></p>

<span lang=EN-IN style='font-size:12.0pt;line-height:115%;font-family:"Verdana",sans-serif'><br
clear=all style='page-break-before:always'>
</span>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>&nbsp;</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>To conclude, we have seen how to
automatically setup an EMR Cluster and then peform data processing on it using
Hive Scripts using Data Pipeline. This was executed On Demand, but the same can
be also scheduled at regular intervals. Also, we have used one Master and one
Slave EC2 instances. But, the Big Data tools like Hive, Spark, Tez can scale to
thousands of EC2 instances for processing TBs and PBs of data.</span></p>

<p class=MsoNormal><span lang=EN-IN style='font-size:12.0pt;line-height:115%;
font-family:"Verdana",sans-serif'>As of this writing it costs 0.48 USD per hour
for On Demand Instances and 0.2556 USD per hour for Spot Instances. Note that
this includes the EMR pricing and we are priced per second, so exactly what we
have used for. The Data Pipeline would try to setup EMR Cluster using Spot
Instances and if for some reason the Spot Instances are not available and then
On Demand Instances would be used. Also, keep in mind that the Spot Instances
can be terminated any point of time.</span></p>

</div>

</body>

</html>
